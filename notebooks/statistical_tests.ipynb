{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, kruskal, mannwhitneyu\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "defa_ft = pd.read_csv('data/scores/scores_default_finetune.csv')\n",
    "defa_st = pd.read_csv('data/scores/scores_default_scratch.csv')\n",
    "segr_ft = pd.read_csv('data/scores/scores_segresnet_finetune.csv')\n",
    "segr_st = pd.read_csv('data/scores/scores_segresnet_scratch.csv')\n",
    "tver_ft = pd.read_csv('data/scores/scores_tverskybce_finetune.csv')\n",
    "tver_st = pd.read_csv('data/scores/scores_tverskybce_scratch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = defa_ft.columns.tolist()\n",
    "columns = [col for col in columns if col != 'sample'] # ignore the ids\n",
    "ids = defa_ft['sample'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['DICE_et',\n",
       "  'DICE_tc',\n",
       "  'DICE_wt',\n",
       "  'Hausdorff_et',\n",
       "  'Hausdorff_tc',\n",
       "  'Hausdorff_wt',\n",
       "  'Sensitivity_et',\n",
       "  'Sensitivity_tc',\n",
       "  'Sensitivity_wt',\n",
       "  'Specificity_et',\n",
       "  'Specificity_tc',\n",
       "  'Specificity_wt',\n",
       "  'True_volume_et',\n",
       "  'True_volume_tc',\n",
       "  'True_volume_wt',\n",
       "  'Predicted_volume_et',\n",
       "  'Predicted_volume_tc',\n",
       "  'Predicted_volume_wt'],\n",
       " ['SBT-MET-B000730-20180517.nii.gz',\n",
       "  'SBT-MET-A000726-20180528.nii.gz',\n",
       "  'SBT-MET-A000727-20180724.nii.gz',\n",
       "  'SBT-MET-A000728-20180326.nii.gz',\n",
       "  'SBT-MET-A000729-20181109.nii.gz',\n",
       "  'SBT-MET-B000731-20180316.nii.gz',\n",
       "  'SBT-MET-B000732-20161017.nii.gz',\n",
       "  'SBT-MET-B000733-20181114.nii.gz',\n",
       "  'SBT-MET-B000734-20180423.nii.gz',\n",
       "  'SBT-MET-D000739-20180319.nii.gz'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuned vs scratch-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check normality of Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'default_finetune'   : defa_ft,\n",
    "    'default_scratch'    : defa_st,\n",
    "    'segresnet_finetune' : segr_ft,\n",
    "    'segresnet_scratch'  : segr_st,\n",
    "    'tverskybce_finetune': tver_ft,\n",
    "    'tverskybce_scratch' : tver_st\n",
    "}\n",
    "\n",
    "def check_normality(dataframes, metric_columns):\n",
    "    normality_results = {}\n",
    "    for model, df in dataframes.items():\n",
    "        normality_results[model] = {}\n",
    "        for metric_column in metric_columns:\n",
    "            stat, p_value = shapiro(df[metric_column])\n",
    "            is_normal = \"Normal\" if p_value > 0.05 else \"Not Normal\"\n",
    "            normality_results[model][metric_column] = {'W-statistic': stat, 'p-value': p_value, 'Normality': is_normal}\n",
    "    \n",
    "    return normality_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             W-statistic   p-value   Normality\n",
      "default_finetune    DICE_et     0.912360  0.297596      Normal\n",
      "                    DICE_tc     0.596355  0.000050  Not Normal\n",
      "                    DICE_wt     0.885041  0.149012      Normal\n",
      "default_scratch     DICE_et     0.937942  0.530351      Normal\n",
      "                    DICE_tc     0.731380  0.002118  Not Normal\n",
      "                    DICE_wt     0.960990  0.797102      Normal\n",
      "segresnet_finetune  DICE_et     0.897431  0.205272      Normal\n",
      "                    DICE_tc     0.522722  0.000007  Not Normal\n",
      "                    DICE_wt     0.901460  0.227315      Normal\n",
      "segresnet_scratch   DICE_et     0.890584  0.172164      Normal\n",
      "                    DICE_tc     0.627135  0.000117  Not Normal\n",
      "                    DICE_wt     0.926187  0.411448      Normal\n",
      "tverskybce_finetune DICE_et     0.866469  0.090908      Normal\n",
      "                    DICE_tc     0.884365  0.146394      Normal\n",
      "                    DICE_wt     0.929221  0.440274      Normal\n",
      "tverskybce_scratch  DICE_et     0.917322  0.335163      Normal\n",
      "                    DICE_tc     0.765810  0.005560  Not Normal\n",
      "                    DICE_wt     0.862478  0.081612      Normal\n",
      "\n",
      "                                  W-statistic   p-value   Normality\n",
      "default_finetune    Hausdorff_et     0.741483  0.002811  Not Normal\n",
      "                    Hausdorff_tc     0.684514  0.000572  Not Normal\n",
      "                    Hausdorff_wt     0.875528  0.115889      Normal\n",
      "default_scratch     Hausdorff_et     0.808575  0.018427  Not Normal\n",
      "                    Hausdorff_tc     0.549885  0.000014  Not Normal\n",
      "                    Hausdorff_wt     0.830622  0.034043  Not Normal\n",
      "segresnet_finetune  Hausdorff_et     0.603379  0.000061  Not Normal\n",
      "                    Hausdorff_tc     0.480011  0.000002  Not Normal\n",
      "                    Hausdorff_wt     0.868894  0.097039      Normal\n",
      "segresnet_scratch   Hausdorff_et     0.711103  0.001201  Not Normal\n",
      "                    Hausdorff_tc     0.736143  0.002420  Not Normal\n",
      "                    Hausdorff_wt     0.906746  0.259377      Normal\n",
      "tverskybce_finetune Hausdorff_et     0.835088  0.038525  Not Normal\n",
      "                    Hausdorff_tc     0.848058  0.055077      Normal\n",
      "                    Hausdorff_wt     0.869852  0.099568      Normal\n",
      "tverskybce_scratch  Hausdorff_et     0.711141  0.001202  Not Normal\n",
      "                    Hausdorff_tc     0.594110  0.000047  Not Normal\n",
      "                    Hausdorff_wt     0.846756  0.053143      Normal\n",
      "\n",
      "                                    W-statistic   p-value   Normality\n",
      "default_finetune    Sensitivity_et     0.811753  0.020137  Not Normal\n",
      "                    Sensitivity_tc     0.651884  0.000231  Not Normal\n",
      "                    Sensitivity_wt     0.903172  0.237302      Normal\n",
      "default_scratch     Sensitivity_et     0.862394  0.081427      Normal\n",
      "                    Sensitivity_tc     0.769512  0.006169  Not Normal\n",
      "                    Sensitivity_wt     0.934973  0.498545      Normal\n",
      "segresnet_finetune  Sensitivity_et     0.819062  0.024688  Not Normal\n",
      "                    Sensitivity_tc     0.577315  0.000030  Not Normal\n",
      "                    Sensitivity_wt     0.898333  0.210034      Normal\n",
      "segresnet_scratch   Sensitivity_et     0.843859  0.049074  Not Normal\n",
      "                    Sensitivity_tc     0.705806  0.001036  Not Normal\n",
      "                    Sensitivity_wt     0.866308  0.090514      Normal\n",
      "tverskybce_finetune Sensitivity_et     0.734685  0.002323  Not Normal\n",
      "                    Sensitivity_tc     0.799958  0.014481  Not Normal\n",
      "                    Sensitivity_wt     0.860159  0.076639      Normal\n",
      "tverskybce_scratch  Sensitivity_et     0.797474  0.013509  Not Normal\n",
      "                    Sensitivity_tc     0.687262  0.000618  Not Normal\n",
      "                    Sensitivity_wt     0.839545  0.043574  Not Normal\n",
      "\n",
      "                                    W-statistic   p-value   Normality\n",
      "default_finetune    Specificity_et     0.745282  0.003127  Not Normal\n",
      "                    Specificity_tc     0.949467  0.662200      Normal\n",
      "                    Specificity_wt     0.730454  0.002064  Not Normal\n",
      "default_scratch     Specificity_et     0.728505  0.001954  Not Normal\n",
      "                    Specificity_tc     0.839583  0.043620  Not Normal\n",
      "                    Specificity_wt     0.784105  0.009289  Not Normal\n",
      "segresnet_finetune  Specificity_et     0.762772  0.005106  Not Normal\n",
      "                    Specificity_tc     0.878273  0.124660      Normal\n",
      "                    Specificity_wt     0.627209  0.000117  Not Normal\n",
      "segresnet_scratch   Specificity_et     0.747485  0.003326  Not Normal\n",
      "                    Specificity_tc     0.851900  0.061191      Normal\n",
      "                    Specificity_wt     0.734877  0.002336  Not Normal\n",
      "tverskybce_finetune Specificity_et     0.781673  0.008676  Not Normal\n",
      "                    Specificity_tc     0.898276  0.209728      Normal\n",
      "                    Specificity_wt     0.939219  0.544360      Normal\n",
      "tverskybce_scratch  Specificity_et     0.785815  0.009745  Not Normal\n",
      "                    Specificity_tc     0.882447  0.139196      Normal\n",
      "                    Specificity_wt     0.934740  0.496098      Normal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric in ['DICE', 'Hausdorff', 'Sensitivity', 'Specificity']:\n",
    "    normality_results_all = check_normality(\n",
    "        dataframes,\n",
    "        metric_columns=[f'{metric}_et', f'{metric}_tc', f'{metric}_wt']\n",
    "    )\n",
    "    normality_df = pd.DataFrame.from_dict({(i,j): normality_results_all[i][j] \n",
    "                                        for i in normality_results_all.keys() \n",
    "                                        for j in normality_results_all[i].keys()},\n",
    "                                        orient='index')\n",
    "\n",
    "    print(normality_df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-parametric test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_finetuned_vs_scratch(dataframes, fine_tuned_models, scratch_models, metric_columns):\n",
    "    comparison_results = {}\n",
    "    for metric_column in metric_columns:\n",
    "        fine_tuned_scores = pd.concat([dataframes[model][metric_column] for model in fine_tuned_models])\n",
    "        scratch_scores = pd.concat([dataframes[model][metric_column] for model in scratch_models])\n",
    "        u_stat, p_value = mannwhitneyu(fine_tuned_scores, scratch_scores, alternative='greater')\n",
    "        \n",
    "        is_significant = \"Significant\" if p_value < 0.05 else \"Not Significant\"\n",
    "        comparison_results[metric_column] = {\n",
    "            'Mann-Whitney U-statistic': u_stat,\n",
    "            'p-value': p_value,\n",
    "            'Significant Difference': is_significant\n",
    "        }\n",
    "    return comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Mann-Whitney U-statistic   p-value Significant Difference\n",
      "DICE_et                    481.0  0.326022        Not Significant\n",
      "DICE_tc                    551.0  0.068661        Not Significant\n",
      "DICE_wt                    465.0  0.415128        Not Significant\n",
      "\n",
      "             Mann-Whitney U-statistic   p-value Significant Difference\n",
      "Hausdorff_et                    364.0  0.899701        Not Significant\n",
      "Hausdorff_tc                    233.5  0.999393        Not Significant\n",
      "Hausdorff_wt                    451.0  0.497045        Not Significant\n",
      "\n",
      "               Mann-Whitney U-statistic   p-value Significant Difference\n",
      "Sensitivity_et                    491.0  0.274663        Not Significant\n",
      "Sensitivity_tc                    517.0  0.162763        Not Significant\n",
      "Sensitivity_wt                    475.0  0.358594        Not Significant\n",
      "\n",
      "               Mann-Whitney U-statistic   p-value Significant Difference\n",
      "Specificity_et                    434.0  0.596364        Not Significant\n",
      "Specificity_tc                    462.0  0.432497        Not Significant\n",
      "Specificity_wt                    430.0  0.619086        Not Significant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_models = ['default_finetune', 'segresnet_finetune', 'tverskybce_finetune']\n",
    "scratch_models    = ['default_scratch' , 'segresnet_scratch' , 'tverskybce_scratch' ]\n",
    "\n",
    "for metric in ['DICE', 'Hausdorff', 'Sensitivity', 'Specificity']:\n",
    "    comparison_results = compare_finetuned_vs_scratch(\n",
    "    dataframes,\n",
    "    fine_tuned_models,\n",
    "    scratch_models,\n",
    "    metric_columns=[f'{metric}_et', f'{metric}_tc', f'{metric}_wt']\n",
    ")\n",
    "    comparison_df = pd.DataFrame(comparison_results).T\n",
    "    print(comparison_df)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architectures comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normality(dataframes, metric_columns):\n",
    "    normality_results = {}\n",
    "    for model, df in dataframes.items():\n",
    "        normality_results[model] = {}\n",
    "        for metric_column in metric_columns:\n",
    "            stat, p_value = shapiro(df[metric_column])\n",
    "            is_normal = \"Normal\" if p_value > 0.05 else \"Not Normal\"\n",
    "            normality_results[model][metric_column] = {'W-statistic': stat, 'p-value': p_value, 'Normality': is_normal}\n",
    "    \n",
    "    return normality_results\n",
    "\n",
    "def compare_architectures(dataframes, architecture_groups, metric_columns):\n",
    "    comparison_results = {}\n",
    "    for metric_column in metric_columns:\n",
    "\n",
    "        # Gather the scores for each architecture\n",
    "        default_scores = pd.concat([dataframes[model][metric_column] for model in architecture_groups['default']])\n",
    "        segresnet_scores = pd.concat([dataframes[model][metric_column] for model in architecture_groups['segresnet']])\n",
    "        tverskybce_scores = pd.concat([dataframes[model][metric_column] for model in architecture_groups['tverskybce']])\n",
    "        \n",
    "        # Perform the Kruskal-Wallis test for significant differences\n",
    "        stat, p_value = kruskal(default_scores, segresnet_scores, tverskybce_scores)\n",
    "        is_significant = \"Significant\" if p_value < 0.05 else \"Not Significant\"\n",
    "        \n",
    "        # Store the results\n",
    "        comparison_results[metric_column] = {\n",
    "            'Kruskal-Wallis H-statistic': stat,\n",
    "            'p-value': p_value,\n",
    "            'Significant Difference': is_significant\n",
    "        }\n",
    "    \n",
    "    return comparison_results\n",
    "\n",
    "def pairwise_compare_architectures(dataframes, architecture_groups, metric_columns):\n",
    "    pairwise_comparisons = {}\n",
    "    architecture_pairs = [\n",
    "        ('tverskybce', 'segresnet'),\n",
    "        ('tverskybce', 'default'),\n",
    "        ('segresnet', 'default'),\n",
    "    ]\n",
    "    \n",
    "    for metric_column in metric_columns:\n",
    "        pairwise_comparisons[metric_column] = {}\n",
    "        \n",
    "        for arch1, arch2 in architecture_pairs:\n",
    "            # Gather the scores for the two architectures\n",
    "            arch1_scores = pd.concat([dataframes[model][metric_column] for model in architecture_groups[arch1]])\n",
    "            arch2_scores = pd.concat([dataframes[model][metric_column] for model in architecture_groups[arch2]])\n",
    "            \n",
    "            # Perform the Mann-Whitney U test\n",
    "            stat, p_value = mannwhitneyu(arch1_scores, arch2_scores, alternative='greater')\n",
    "            is_significant = \"Significantly greater\" if p_value < 0.05 else \"\"\n",
    "            \n",
    "            # Store the results\n",
    "            pairwise_comparisons[metric_column][f'{arch1} vs {arch2}'] = f'p_value={p_value:.2f} => {is_significant}'\n",
    "            # pairwise_comparisons[metric_column][f'{arch1} vs {arch2}'] = {\n",
    "            #     'Mann-Whitney U-statistic': stat,\n",
    "            #     'p-value': p_value,\n",
    "            #     'Significant Difference': is_significant\n",
    "            # }\n",
    "    \n",
    "    return pairwise_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       tverskybce vs segresnet  \\\n",
      "DICE_et                       p_value=0.48 =>    \n",
      "DICE_tc                       p_value=0.59 =>    \n",
      "DICE_wt  p_value=0.04 => Significantly greater   \n",
      "\n",
      "                         tverskybce vs default segresnet vs default  \n",
      "DICE_et                       p_value=0.55 =>      p_value=0.62 =>   \n",
      "DICE_tc                       p_value=0.69 =>      p_value=0.63 =>   \n",
      "DICE_wt  p_value=0.04 => Significantly greater     p_value=0.49 =>   \n",
      "             tverskybce vs segresnet tverskybce vs default  \\\n",
      "Hausdorff_et        p_value=0.37 =>       p_value=0.42 =>    \n",
      "Hausdorff_tc        p_value=0.72 =>       p_value=0.82 =>    \n",
      "Hausdorff_wt        p_value=0.75 =>       p_value=0.88 =>    \n",
      "\n",
      "             segresnet vs default  \n",
      "Hausdorff_et     p_value=0.53 =>   \n",
      "Hausdorff_tc     p_value=0.54 =>   \n",
      "Hausdorff_wt     p_value=0.72 =>   \n",
      "                              tverskybce vs segresnet  \\\n",
      "Sensitivity_et  p_value=0.01 => Significantly greater   \n",
      "Sensitivity_tc  p_value=0.01 => Significantly greater   \n",
      "Sensitivity_wt  p_value=0.00 => Significantly greater   \n",
      "\n",
      "                                tverskybce vs default segresnet vs default  \n",
      "Sensitivity_et  p_value=0.01 => Significantly greater     p_value=0.57 =>   \n",
      "Sensitivity_tc  p_value=0.01 => Significantly greater     p_value=0.51 =>   \n",
      "Sensitivity_wt  p_value=0.00 => Significantly greater     p_value=0.59 =>   \n",
      "               tverskybce vs segresnet tverskybce vs default  \\\n",
      "Specificity_et        p_value=0.98 =>       p_value=0.98 =>    \n",
      "Specificity_tc        p_value=1.00 =>       p_value=1.00 =>    \n",
      "Specificity_wt        p_value=1.00 =>       p_value=1.00 =>    \n",
      "\n",
      "               segresnet vs default  \n",
      "Specificity_et     p_value=0.53 =>   \n",
      "Specificity_tc     p_value=0.73 =>   \n",
      "Specificity_wt     p_value=0.47 =>   \n"
     ]
    }
   ],
   "source": [
    "architecture_groups = {\n",
    "    'default'   : ['default_finetune', 'default_scratch'],\n",
    "    'segresnet' : ['segresnet_finetune', 'segresnet_scratch'],\n",
    "    'tverskybce': ['tverskybce_finetune', 'tverskybce_scratch']\n",
    "}\n",
    "architecture_comparison_dfs = []\n",
    "\n",
    "for metric in ['DICE', 'Hausdorff', 'Sensitivity', 'Specificity']:\n",
    "    architecture_comparison_results = pairwise_compare_architectures(\n",
    "        dataframes,\n",
    "        architecture_groups,\n",
    "        metric_columns=[f'{metric}_et', f'{metric}_tc', f'{metric}_wt']\n",
    "    )\n",
    "\n",
    "    architecture_comparison_df = pd.DataFrame(architecture_comparison_results).T\n",
    "    architecture_comparison_dfs.append(architecture_comparison_df)\n",
    "    print(architecture_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tverskybce vs segresnet</th>\n",
       "      <th>tverskybce vs default</th>\n",
       "      <th>segresnet vs default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DICE_et</th>\n",
       "      <td>p_value=0.48 =&gt;</td>\n",
       "      <td>p_value=0.55 =&gt;</td>\n",
       "      <td>p_value=0.62 =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DICE_tc</th>\n",
       "      <td>p_value=0.59 =&gt;</td>\n",
       "      <td>p_value=0.69 =&gt;</td>\n",
       "      <td>p_value=0.63 =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DICE_wt</th>\n",
       "      <td>p_value=0.04 =&gt; Significantly greater</td>\n",
       "      <td>p_value=0.04 =&gt; Significantly greater</td>\n",
       "      <td>p_value=0.49 =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hausdorff_et</th>\n",
       "      <td>p_value=0.37 =&gt;</td>\n",
       "      <td>p_value=0.42 =&gt;</td>\n",
       "      <td>p_value=0.53 =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hausdorff_tc</th>\n",
       "      <td>p_value=0.72 =&gt;</td>\n",
       "      <td>p_value=0.82 =&gt;</td>\n",
       "      <td>p_value=0.54 =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hausdorff_wt</th>\n",
       "      <td>p_value=0.75 =&gt;</td>\n",
       "      <td>p_value=0.88 =&gt;</td>\n",
       "      <td>p_value=0.72 =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity_et</th>\n",
       "      <td>p_value=0.01 =&gt; Significantly greater</td>\n",
       "      <td>p_value=0.01 =&gt; Significantly greater</td>\n",
       "      <td>p_value=0.57 =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity_tc</th>\n",
       "      <td>p_value=0.01 =&gt; Significantly greater</td>\n",
       "      <td>p_value=0.01 =&gt; Significantly greater</td>\n",
       "      <td>p_value=0.51 =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity_wt</th>\n",
       "      <td>p_value=0.00 =&gt; Significantly greater</td>\n",
       "      <td>p_value=0.00 =&gt; Significantly greater</td>\n",
       "      <td>p_value=0.59 =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity_et</th>\n",
       "      <td>p_value=0.98 =&gt;</td>\n",
       "      <td>p_value=0.98 =&gt;</td>\n",
       "      <td>p_value=0.53 =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity_tc</th>\n",
       "      <td>p_value=1.00 =&gt;</td>\n",
       "      <td>p_value=1.00 =&gt;</td>\n",
       "      <td>p_value=0.73 =&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity_wt</th>\n",
       "      <td>p_value=1.00 =&gt;</td>\n",
       "      <td>p_value=1.00 =&gt;</td>\n",
       "      <td>p_value=0.47 =&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              tverskybce vs segresnet  \\\n",
       "DICE_et                              p_value=0.48 =>    \n",
       "DICE_tc                              p_value=0.59 =>    \n",
       "DICE_wt         p_value=0.04 => Significantly greater   \n",
       "Hausdorff_et                         p_value=0.37 =>    \n",
       "Hausdorff_tc                         p_value=0.72 =>    \n",
       "Hausdorff_wt                         p_value=0.75 =>    \n",
       "Sensitivity_et  p_value=0.01 => Significantly greater   \n",
       "Sensitivity_tc  p_value=0.01 => Significantly greater   \n",
       "Sensitivity_wt  p_value=0.00 => Significantly greater   \n",
       "Specificity_et                       p_value=0.98 =>    \n",
       "Specificity_tc                       p_value=1.00 =>    \n",
       "Specificity_wt                       p_value=1.00 =>    \n",
       "\n",
       "                                tverskybce vs default segresnet vs default  \n",
       "DICE_et                              p_value=0.55 =>      p_value=0.62 =>   \n",
       "DICE_tc                              p_value=0.69 =>      p_value=0.63 =>   \n",
       "DICE_wt         p_value=0.04 => Significantly greater     p_value=0.49 =>   \n",
       "Hausdorff_et                         p_value=0.42 =>      p_value=0.53 =>   \n",
       "Hausdorff_tc                         p_value=0.82 =>      p_value=0.54 =>   \n",
       "Hausdorff_wt                         p_value=0.88 =>      p_value=0.72 =>   \n",
       "Sensitivity_et  p_value=0.01 => Significantly greater     p_value=0.57 =>   \n",
       "Sensitivity_tc  p_value=0.01 => Significantly greater     p_value=0.51 =>   \n",
       "Sensitivity_wt  p_value=0.00 => Significantly greater     p_value=0.59 =>   \n",
       "Specificity_et                       p_value=0.98 =>      p_value=0.53 =>   \n",
       "Specificity_tc                       p_value=1.00 =>      p_value=0.73 =>   \n",
       "Specificity_wt                       p_value=1.00 =>      p_value=0.47 =>   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_df = pd.concat(architecture_comparison_dfs)\n",
    "ac_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metaseg-ROJnLKGW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
